}
c_fun <- function(d,m){
p <- NULL
for (i in 1:length(m[,1])) {
x <- rbind(d,m[i,])
di <- dist(x, method = 'euclidean')
p <- cbind(p,di)
}
p <- which.min(p)
return(p)
}
g <- k_means_shiny(6)
med_dat <- read.delim('C:/Users/abig4/OneDrive/Documents/GitHub/Statistical-Learning_Lab_2/gtex_Kmeans/gtex.gct',
skip = 2 ,row.names=c(1) , header = TRUE)
#med_dat <- read.delim('C:/Users/abig4/OneDrive/Documents/GitHub/Statistical-Learning_Lab_2/gtex_Kmeans/gtex.gct', skip = 2 ,row.names=c(1) , header = TRUE)
med_dat <- read.delim("C:/Users/Shahar/Documents/GitHub/Statistical-Learning_Lab_2/gtex_Kmeans/gtex.gct", skip = 2 ,row.names=c(1) , header = TRUE)
gen_names <- med_dat[, 1]
med_dat <- med_dat[,-1]
ti_name <- colnames(med_dat)
med_dat <- transpose(med_dat)
med_dat <-med_dat[,colMeans(med_dat) > 0]
v <- apply(med_dat,2, var)
med_dat <-med_dat[, v != 0]
#med_dat <- as.data.frame(scale(med_dat,T,T))
m <- prcomp(med_dat,scale. = T,center = T)
sv <-m$sdev^2/sum(m$sdev^2)
sv <- cumsum(sv)
sv <- length(sv[sv < 0.9])
m <- m$x[,1:sv]
k_means_shiny <- function(k){
data_prep <- m
m_new <- as.data.frame(data_prep[sample(1:53,k),])
clus <- apply(data_prep,1 ,FUN = c_fun, m=m_new)
m_old <- as.data.frame(data_prep[sample(1:53,k),])
data_prep <- cbind(data_prep, clus)
iter <- 1
while(any(abs(m_new - m_old)) > 0.1 & iter < 1){
data_prep <- as.data.frame(data_prep)
m_old <- m_new
m_new <- aggregate(. ~ clus, data_prep, FUN = mean)
m_new <- m_new[,-1]
data_prep$clus<- data_prep[,-1]  %>% apply(1,FUN = c_fun,m = m_new)
print(m_new)
print(m_old)
iter <- iter +1
}
return(data_prep)
}
c_fun <- function(d,m){
p <- NULL
for (i in 1:length(m[,1])) {
x <- rbind(d,m[i,])
di <- dist(x, method = 'euclidean')
p <- cbind(p,di)
}
p <- which.min(p)
return(p)
}
g <- k_means_shiny(6)
g
library('MASS')
library(data.table)
library(ggplot2)
library(kableExtra)
library(dplyr)
library(dendextend)
library(readxl)
library(fuzzyjoin)
library(stringr)
library(ggdendro)
library(factoextra)
options(scipen = 999)
ob <- c(rep(1,20),rep(2,30),rep(3,50))
sampling <- NULL
for (i in 1:10) {
first_10 <- rnorm(3,0,1) #mu
sampling <- rbind(sampling,first_10)
colnames(sampling) <- c(1:3)
}
calculate.accuracy <- function(data, cluster_data){
tab <- table(data,cluster_data)
s <- 0
b <- NULL
for(i in 1:3){
w<- tab[,i]
m <- max(w)
wm <- which.max(w)
while(wm %in% b){
w <- w[-wm,]
m <- max(w)
wm <- colnames(w)[which.max(w)]
}
s<- s+m
}
s <- s/100
return(s)
}
multi_fun <- function(s){
start.time <- Sys.time()
model <- kmeans(s,3,1,algorithm = "Lloyd")
end.time <- Sys.time()
time.taken <- end.time - start.time
accurancy <- model$cluster
accurancy <- calculate.accuracy(accurancy,ob)
return(list(accurancy,time.taken))
}
create_data <- function(sampling, p, sigma_e){
x_data <- NULL
if(p >10){
mu_num <- rep(0,(p - 10))
mu <- cbind(mu_num, mu_num, mu_num)
mu <- rbind(sampling,mu)
mu <- as.data.frame(mu)
} else {
mu <- as.data.frame(sampling)
}
d <- diag(sqrt(rep(sigma_e,p)))
dat_a = mvrnorm(20,mu = mu[,1],Sigma=  d)
dat_b = mvrnorm(30,mu = mu[,2],Sigma=  d)
dat_c = mvrnorm(50,mu = mu[,3],Sigma=  d)
x_data = rbind(dat_a, dat_b,dat_c)
return(x_data)
}
sigma_list <- c(1,2,6,9)
p <- c(10,20,50)
simulation <- function(sampling,p,sigma_list,B){
s_total <- NULL
for (i in p) {
for (j in sigma_list) {
s <- NULL
s <- replicate(n = B,sampling,simplify = F)
s <- lapply(s,create_data,p = i,sigma_e = j)
s <- lapply(s, multi_fun)
s_total <- cbind(s_total,s)
}
}
return(s_total)
}
gene <- simulation(sampling,p,sigma_list,50)
l <- c(paste0("p = ",10, ",sigma = ",1),paste0("p = ",10, ",sigma = ",2),
paste0("p = ",10, ",sigma = ",6),paste0("p = ",10, ",sigma = ",9),
paste0("p = ",20, ",sigma = ",1),paste0("p = ",20, ",sigma = ",2),
paste0("p = ",20, ",sigma = ",6),paste0("p = ",20, ",sigma = ",9),
paste0("p = ",50, ",sigma = ",1),paste0("p = ",50, ",sigma = ",2),
paste0("p = ",50, ",sigma = ",6),paste0("p = ",50, ",sigma = ",9))
k_sh_p <- c(rep(10,4),rep(20,4),rep(50,4))
k_col_sig <- rep(sigma_list,3)
temp <- NULL
temp2 <- NULL
for(i in 1:12){
df <- gene[,i]
df <- rbindlist(lapply(df, as.data.frame.list))
colnames(df) <- c("accurancy", "run.time")
temp2 <- rbind(temp2,list(df))
df <- round(c(avg = mean(df$accurancy),sd_accurancy = sd(df$accurancy)/sqrt(50)),3)
temp <- rbind(temp,df)
}
names(temp2) <- l
row.names(temp) <- l
temp <- as.data.frame(temp)
temp <- cbind(temp,k_col_sig,k_sh_p)
temp <- as.data.frame(temp)
ggplot(temp,aes( y = avg,x=factor(k_col_sig))) +
geom_bar(stat="identity",position="dodge") +
facet_grid(~factor(k_sh_p))+
geom_errorbar(data = temp,aes(ymin=avg-sd_accurancy,
ymax=avg + sd_accurancy), width=.2,position=position_dodge(.9)) +
geom_text(aes(label=avg), vjust=1.6, color="white", size=3.5)+
facet_grid(~factor(k_sh_p))+ theme_light()  +
xlab("Devided by sigma & p levels")+
ylab("Accurancy Average") +
ggtitle(label = "Averege acurrency bar plot", subtitle = "Caculated over 50 simulations. Displayed by the different sigmas and p with standard error bar") +
theme(plot.title = element_text(hjust = 0.5,size = 20, face = "bold"),
plot.subtitle = element_text(hjust = 0.5,size = 10, face = "bold")) +
theme(legend.title = element_text(color = "black", size = 10),
legend.text = element_text(color = "black")) +
labs(shape="Vectors Variables \n Number", colour="SE of \n the Vectors") + ylim(c(0,1))
kable(temp[,1:2]) %>% kable_styling()
temp2 <-bind_rows(temp2, .id = "column_label")
k_sh_p <- c(rep(10,4*50),rep(20,4*50),rep(50,4*50))
k_col_sig <- rep(rep(sigma_list, each = 50),3)
temp2 <- cbind(temp2,k_col_sig,k_sh_p)
ggplot(temp2, aes(y = run.time, x =factor(k_col_sig))) + facet_grid(~factor(k_sh_p))+
geom_boxplot()+
stat_summary(geom = "point",
fun = "mean", col = "red",size = 1, fill = "red") +
theme_light() + ylim(c(0,0.002))+
xlab("")+ ylab("Run time for K-mean convergence") +
ggtitle(label = "Run time", subtitle = "Displayed by diffrenet sigmas and variable amouמt. \n Mean marked in red point5, Median marked in bold line. \n outliers have been left out.")+
theme(plot.title = element_text(hjust = 0.5,size = 20, face = "bold"),
plot.subtitle = element_text(hjust = 0.5,size = 10, face = "bold")) +
theme(axis.text.x = element_text(angle = 00, vjust = 0.5))
#load the data frames
knesset_df <- read.csv("C:/Users/Shahar/Dropbox/zugi/lemida/knesset_24.csv", encoding = "UTF-8")
CBS_df <- read_excel("C:/Users/Shahar/Dropbox/zugi/lemida/t01.xls")
#first, we merge the data frames to find the matching locations in both.
merged_df <- left_join(CBS_df, knesset_df, by = "סמל.ישוב")
#add "שם.ישוב" coloumn to the CBS data frame
names_df <- as.data.frame(knesset_df[,2:3])
CBS_df <- left_join(CBS_df, names_df)
#semple 20 locations
set.seed(20)
Semp_20 <- sample(merged_df$"סמל.ישוב" , 20)
# sum all the votes for each location
#calculate the persents of votes for each party in every location
knesset_df_norm <- knesset_df %>%rowwise %>% mutate(total_votes = sum(c_across( 8:46))) %>% ungroup() %>%  mutate(round(across(8:46, ~ . / total_votes),3))
#filter each data frame for the sempled values.
knesset_semp20 <- filter(knesset_df_norm, knesset_df_norm$"סמל.ישוב" %in% Semp_20)
CBS_semp20 <- filter(CBS_df, CBS_df$"סמל.ישוב" %in% Semp_20)
knesst_dist <- knesset_semp20[,c(8:46)] %>% dist %>% hclust(method = "complete")
knesst_dend <- as.dendrogram(knesst_dist)
labels(knesst_dend) <- as.character(knesset_semp20$'שם.ישוב')
Knesst_plot <- ggplot(knesst_dend %>%
set('branches_lwd', 0.7) %>%
set('labels_cex', 0.8),
horiz = TRUE,  theme = theme_minimal()) +
ggtitle("Hirarchical tree of the 24 election datas with complete linked algorithm", "*Each color present diffrent cluster") + ylab("Distance") + xlab(" ")
Knesst_plot
CBS_dist <- CBS_semp20[,6:17] %>% scale %>% dist %>% hclust(method = "complete")
CBS_dend <- as.dendrogram(CBS_dist)
labels(CBS_dend) <- as.character(CBS_semp20$'שם.ישוב')
CBS_plot <- ggplot(CBS_dend %>%
set('branches_lwd', 0.7) %>%
set('labels_cex', 0.8), horiz = TRUE, theme = theme_minimal()) +
ggtitle("Hirarchical tree of the CBS datas with complete linked algorithm", "*Each color present diffrent cluster")+ ylab("Distance") + xlab(" ")
CBS_plot
dl <- dendlist(highlight_branches_col(knesst_dend), highlight_branches_col(CBS_dend))
tanglegram(dl, sort = TRUE, highlight_distinct_edges  = FALSE, highlight_branches_lwd = FALSE, main_left = "CBS", main_right = "Knesset", dLeaf_left = 0.01 , dLeaf_right = -0.6)
dend <- knesst_dend
dend1 <- CBS_dend
cor <- cor_bakers_gamma(dend,dend1)
print(paste("The correlation between the two dendograms is: ", round(cor,3)))
the_cor <- cor_bakers_gamma(dend,dend) #we see that the correlation between the dend to herself is 1
the_cor2 <- cor_bakers_gamma(dend,dend1) #the correlation between the two dendograms that we created
R <- 100
cor_bakers_gamma_results <- numeric(R)
dend_mixed <- dend
for(i in 1:R) { #compute the corr between the original dendograme to the permutation dendogram
dend_mixed <- sample.dendrogram(dend_mixed, replace = FALSE)
cor_bakers_gamma_results[i] <- cor_bakers_gamma(dend, dend_mixed)
}
plot(density(cor_bakers_gamma_results),
main = "Baker's gamma distribution under H0",
xlim = c(-1,1))
abline(v = 0, lty = 2)
abline(v = the_cor, lty = 2, col = 2)
abline(v = the_cor2, lty = 2, col = 4)
legend("topleft", legend = c("cor", "cor2"), fill = c(2,4))
round(sum(the_cor2 < cor_bakers_gamma_results)/ R, 4)
title(sub = paste("One sided p-value:",
"cor =",  round(sum(the_cor < cor_bakers_gamma_results)/ R, 4),
" ; cor2 =",  round(sum(the_cor2 < cor_bakers_gamma_results)/ R, 4)))
k_means_shiny <- function(k){
data_prep <- m
m_new <- as.data.frame(data_prep[sample(1:53,k),])
clus <- apply(data_prep,1 ,FUN = c_fun, m=m_new)
m_old <- as.data.frame(data_prep[sample(1:53,k),])
data_prep <- cbind(data_prep, clus)
iter <- 1
while(any(abs(m_new - m_old)) > 0.1 & iter < 1){
data_prep <- as.data.frame(data_prep)
m_old <- m_new
m_new <- aggregate(. ~ clus, data_prep, FUN = mean)
m_new <- m_new[,-1]
data_prep$clus<- data_prep[,-1]  %>% apply(1,FUN = c_fun,m = m_new)
print(m_new)
print(m_old)
iter <- iter +1
}
return(data_prep)
}
c_fun <- function(d,m){
p <- NULL
for (i in 1:length(m[,1])) {
x <- rbind(d,m[i,])
di <- dist(x, method = 'euclidean')
p <- cbind(p,di)
}
p <- which.min(p)
return(p)
}
g <- k_means_shiny(6)
library(kableExtra)
install.packages("kableExtra")
install.packages("kableExtra")
library(kableExtra)
library(kableExtra)
kable(temp[,1:2]) %>% kable_styling()
kable(temp[,1:2]) %>% kable_styling()
kable(temp[,1:2]) %>% kable_styling()
library('MASS')
library(data.table)
library(ggplot2)
library(kableExtra)
library(dplyr)
library(dendextend)
library(readxl)
library(fuzzyjoin)
library(stringr)
library(ggdendro)
library(factoextra)
options(scipen = 999)
ob <- c(rep(1,20),rep(2,30),rep(3,50))
sampling <- NULL
for (i in 1:10) {
first_10 <- rnorm(3,0,1) #mu
sampling <- rbind(sampling,first_10)
colnames(sampling) <- c(1:3)
}
calculate.accuracy <- function(data, cluster_data){
tab <- table(data,cluster_data)
s <- 0
b <- NULL
for(i in 1:3){
w<- tab[,i]
m <- max(w)
wm <- which.max(w)
while(wm %in% b){
w <- w[-wm,]
m <- max(w)
wm <- colnames(w)[which.max(w)]
}
s<- s+m
}
s <- s/100
return(s)
}
multi_fun <- function(s){
start.time <- Sys.time()
model <- kmeans(s,3,1,algorithm = "Lloyd")
end.time <- Sys.time()
time.taken <- end.time - start.time
accurancy <- model$cluster
accurancy <- calculate.accuracy(accurancy,ob)
return(list(accurancy,time.taken))
}
create_data <- function(sampling, p, sigma_e){
x_data <- NULL
if(p >10){
mu_num <- rep(0,(p - 10))
mu <- cbind(mu_num, mu_num, mu_num)
mu <- rbind(sampling,mu)
mu <- as.data.frame(mu)
} else {
mu <- as.data.frame(sampling)
}
d <- diag(sqrt(rep(sigma_e,p)))
dat_a = mvrnorm(20,mu = mu[,1],Sigma=  d)
dat_b = mvrnorm(30,mu = mu[,2],Sigma=  d)
dat_c = mvrnorm(50,mu = mu[,3],Sigma=  d)
x_data = rbind(dat_a, dat_b,dat_c)
return(x_data)
}
sigma_list <- c(1,2,6,9)
p <- c(10,20,50)
simulation <- function(sampling,p,sigma_list,B){
s_total <- NULL
for (i in p) {
for (j in sigma_list) {
s <- NULL
s <- replicate(n = B,sampling,simplify = F)
s <- lapply(s,create_data,p = i,sigma_e = j)
s <- lapply(s, multi_fun)
s_total <- cbind(s_total,s)
}
}
return(s_total)
}
gene <- simulation(sampling,p,sigma_list,50)
l <- c(paste0("p = ",10, ",sigma = ",1),paste0("p = ",10, ",sigma = ",2),
paste0("p = ",10, ",sigma = ",6),paste0("p = ",10, ",sigma = ",9),
paste0("p = ",20, ",sigma = ",1),paste0("p = ",20, ",sigma = ",2),
paste0("p = ",20, ",sigma = ",6),paste0("p = ",20, ",sigma = ",9),
paste0("p = ",50, ",sigma = ",1),paste0("p = ",50, ",sigma = ",2),
paste0("p = ",50, ",sigma = ",6),paste0("p = ",50, ",sigma = ",9))
k_sh_p <- c(rep(10,4),rep(20,4),rep(50,4))
k_col_sig <- rep(sigma_list,3)
temp <- NULL
temp2 <- NULL
for(i in 1:12){
df <- gene[,i]
df <- rbindlist(lapply(df, as.data.frame.list))
colnames(df) <- c("accurancy", "run.time")
temp2 <- rbind(temp2,list(df))
df <- round(c(avg = mean(df$accurancy),sd_accurancy = sd(df$accurancy)/sqrt(50)),3)
temp <- rbind(temp,df)
}
names(temp2) <- l
row.names(temp) <- l
temp <- as.data.frame(temp)
temp <- cbind(temp,k_col_sig,k_sh_p)
temp <- as.data.frame(temp)
ggplot(temp,aes( y = avg,x=factor(k_col_sig))) +
geom_bar(stat="identity",position="dodge") +
facet_grid(~factor(k_sh_p))+
geom_errorbar(data = temp,aes(ymin=avg-sd_accurancy,
ymax=avg + sd_accurancy), width=.2,position=position_dodge(.9)) +
geom_text(aes(label=avg), vjust=1.6, color="white", size=3.5)+
facet_grid(~factor(k_sh_p))+ theme_light()  +
xlab("Devided by sigma & p levels")+
ylab("Accurancy Average") +
ggtitle(label = "Averege acurrency bar plot", subtitle = "Caculated over 50 simulations. Displayed by the different sigmas and p with standard error bar") +
theme(plot.title = element_text(hjust = 0.5,size = 20, face = "bold"),
plot.subtitle = element_text(hjust = 0.5,size = 10, face = "bold")) +
theme(legend.title = element_text(color = "black", size = 10),
legend.text = element_text(color = "black")) +
labs(shape="Vectors Variables \n Number", colour="SE of \n the Vectors") + ylim(c(0,1))
kable(temp[,1:2]) %>% kable_styling()
temp2 <-bind_rows(temp2, .id = "column_label")
k_sh_p <- c(rep(10,4*50),rep(20,4*50),rep(50,4*50))
k_col_sig <- rep(rep(sigma_list, each = 50),3)
temp2 <- cbind(temp2,k_col_sig,k_sh_p)
ggplot(temp2, aes(y = run.time, x =factor(k_col_sig))) + facet_grid(~factor(k_sh_p))+
geom_boxplot()+
stat_summary(geom = "point",
fun = "mean", col = "red",size = 1, fill = "red") +
theme_light() + ylim(c(0,0.002))+
xlab("")+ ylab("Run time for K-mean convergence") +
ggtitle(label = "Run time", subtitle = "Displayed by diffrenet sigmas and variable amouמt. \n Mean marked in red point5, Median marked in bold line. \n outliers have been left out.")+
theme(plot.title = element_text(hjust = 0.5,size = 20, face = "bold"),
plot.subtitle = element_text(hjust = 0.5,size = 10, face = "bold")) +
theme(axis.text.x = element_text(angle = 00, vjust = 0.5))
#load the data frames
knesset_df <- read.csv("C:/Users/Shahar/Dropbox/zugi/lemida/knesset_24.csv", encoding = "UTF-8")
CBS_df <- read_excel("C:/Users/Shahar/Dropbox/zugi/lemida/t01.xls")
#first, we merge the data frames to find the matching locations in both.
merged_df <- left_join(CBS_df, knesset_df, by = "סמל.ישוב")
#add "שם.ישוב" coloumn to the CBS data frame
names_df <- as.data.frame(knesset_df[,2:3])
CBS_df <- left_join(CBS_df, names_df)
#semple 20 locations
set.seed(20)
Semp_20 <- sample(merged_df$"סמל.ישוב" , 20)
# sum all the votes for each location
#calculate the persents of votes for each party in every location
knesset_df_norm <- knesset_df %>%rowwise %>% mutate(total_votes = sum(c_across( 8:46))) %>% ungroup() %>%  mutate(round(across(8:46, ~ . / total_votes),3))
#filter each data frame for the sempled values.
knesset_semp20 <- filter(knesset_df_norm, knesset_df_norm$"סמל.ישוב" %in% Semp_20)
CBS_semp20 <- filter(CBS_df, CBS_df$"סמל.ישוב" %in% Semp_20)
knesst_dist <- knesset_semp20[,c(8:46)] %>% dist %>% hclust(method = "complete")
knesst_dend <- as.dendrogram(knesst_dist)
labels(knesst_dend) <- as.character(knesset_semp20$'שם.ישוב')
Knesst_plot <- ggplot(knesst_dend %>%
set('branches_lwd', 0.7) %>%
set('labels_cex', 0.8),
horiz = TRUE,  theme = theme_minimal()) +
ggtitle("Hirarchical tree of the 24 election datas with complete linked algorithm", "*Each color present diffrent cluster") + ylab("Distance") + xlab(" ")
Knesst_plot
CBS_dist <- CBS_semp20[,6:17] %>% scale %>% dist %>% hclust(method = "complete")
CBS_dend <- as.dendrogram(CBS_dist)
labels(CBS_dend) <- as.character(CBS_semp20$'שם.ישוב')
CBS_plot <- ggplot(CBS_dend %>%
set('branches_lwd', 0.7) %>%
set('labels_cex', 0.8), horiz = TRUE, theme = theme_minimal()) +
ggtitle("Hirarchical tree of the CBS datas with complete linked algorithm", "*Each color present diffrent cluster")+ ylab("Distance") + xlab(" ")
CBS_plot
dl <- dendlist(highlight_branches_col(knesst_dend), highlight_branches_col(CBS_dend))
tanglegram(dl, sort = TRUE, highlight_distinct_edges  = FALSE, highlight_branches_lwd = FALSE, main_left = "CBS", main_right = "Knesset", dLeaf_left = 0.01 , dLeaf_right = -0.6)
dend <- knesst_dend
dend1 <- CBS_dend
cor <- cor_bakers_gamma(dend,dend1)
print(paste("The correlation between the two dendograms is: ", round(cor,3)))
the_cor <- cor_bakers_gamma(dend,dend) #we see that the correlation between the dend to herself is 1
the_cor2 <- cor_bakers_gamma(dend,dend1) #the correlation between the two dendograms that we created
R <- 100
cor_bakers_gamma_results <- numeric(R)
dend_mixed <- dend
for(i in 1:R) { #compute the corr between the original dendograme to the permutation dendogram
dend_mixed <- sample.dendrogram(dend_mixed, replace = FALSE)
cor_bakers_gamma_results[i] <- cor_bakers_gamma(dend, dend_mixed)
}
plot(density(cor_bakers_gamma_results),
main = "Baker's gamma distribution under H0",
xlim = c(-1,1))
abline(v = 0, lty = 2)
abline(v = the_cor, lty = 2, col = 2)
abline(v = the_cor2, lty = 2, col = 4)
legend("topleft", legend = c("cor", "cor2"), fill = c(2,4))
round(sum(the_cor2 < cor_bakers_gamma_results)/ R, 4)
title(sub = paste("One sided p-value:",
"cor =",  round(sum(the_cor < cor_bakers_gamma_results)/ R, 4),
" ; cor2 =",  round(sum(the_cor2 < cor_bakers_gamma_results)/ R, 4)))
k_means_shiny <- function(k){
data_prep <- m
m_new <- as.data.frame(data_prep[sample(1:53,k),])
clus <- apply(data_prep,1 ,FUN = c_fun, m=m_new)
m_old <- as.data.frame(data_prep[sample(1:53,k),])
data_prep <- cbind(data_prep, clus)
iter <- 1
while(any(abs(m_new - m_old)) > 0.1 & iter < 1){
data_prep <- as.data.frame(data_prep)
m_old <- m_new
m_new <- aggregate(. ~ clus, data_prep, FUN = mean)
m_new <- m_new[,-1]
data_prep$clus<- data_prep[,-1]  %>% apply(1,FUN = c_fun,m = m_new)
print(m_new)
print(m_old)
iter <- iter +1
}
return(data_prep)
}
c_fun <- function(d,m){
p <- NULL
for (i in 1:length(m[,1])) {
x <- rbind(d,m[i,])
di <- dist(x, method = 'euclidean')
p <- cbind(p,di)
}
p <- which.min(p)
return(p)
}
g <- k_means_shiny(6)
