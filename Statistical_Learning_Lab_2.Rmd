---
title: "Statistical Learning and Data Analysis 2021 - 52525"
author: 'Abigail Gutman and Shahar Shalom '
date: "18/5/2021"
output:
  html_document: default
  pdf_document: default
subtitle: Lab 2 - Elections and RNA-sequencing
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
library('MASS')
library(data.table)
library(ggplot2)
library(kableExtra)
library(dplyr)
library(dendextend)
library(readxl)
library(fuzzyjoin)
library(stringr)
library(ggdendro)
library(factoextra)
```

# **1. Simulation Study:**

### Q1:
Generate the first 10 coordinates of each µj vector j = 1, ..,3
```{r, warning=FALSE}
options(scipen = 999)

ob <- c(rep(1,20),rep(2,30),rep(3,50))
sampling <- NULL

for (i in 1:10) {
first_10 <- rnorm(3,0,1) #mu
sampling <- rbind(sampling,first_10)
colnames(sampling) <- c(1:3)
}
```



```{r}
calculate.accuracy <- function(data, cluster_data){
  tab <- table(data,cluster_data)
  s <- 0
  b <- NULL
  for(i in 1:3){
    w<- tab[,i]
    m <- max(w)
    wm <- which.max(w)
    while(wm %in% b){
      w <- w[-wm,]
      m <- max(w)
      wm <- colnames(w)[which.max(w)]
    }
    s<- s+m
  }
  s <- s/100
  return(s)
  }
```



```{r}

multi_fun <- function(s){
  start.time <- Sys.time()
  model <- kmeans(s,3,1,algorithm = "Lloyd")
  end.time <- Sys.time()
  time.taken <- end.time - start.time
  accurancy <- model$cluster
  accurancy <- calculate.accuracy(accurancy,ob)
  return(list(accurancy,time.taken))
}

```

### Q2:
Write a function that outputs a simulated dataset of dimension (100 × p)
```{r}
create_data <- function(sampling, p, sigma_e){
  x_data <- NULL
  if(p >10){
  mu_num <- rep(0,(p - 10))
  mu <- cbind(mu_num, mu_num, mu_num)
  mu <- rbind(sampling,mu)
  mu <- as.data.frame(mu) 
  } else {
    mu <- as.data.frame(sampling)
  }
  d <- diag(sqrt(rep(sigma_e,p)))
  dat_a = mvrnorm(20,mu = mu[,1],Sigma=  d)
  dat_b = mvrnorm(30,mu = mu[,2],Sigma=  d)
  dat_c = mvrnorm(50,mu = mu[,3],Sigma=  d)
  x_data = rbind(dat_a, dat_b,dat_c)
  return(x_data)
}
```

### Q3
Choose 4 levels of σ^2 and use p = 10, 20, 50.
choosing sigma : 1,2,6,9

### Q4
For each combination of σ^2 and p, generate multiple datasets (say B = 50).

### Q5
For each data-set, run K-means once on the p dimensional data, and save accuracy and
run-time.
```{r, warning=FALSE}
sigma_list <- c(1,2,6,9)
p <- c(10,20,50)
simulation <- function(sampling,p,sigma_list,B){
  s_total <- NULL
  for (i in p) {
    for (j in sigma_list) {
      s <- NULL
      s <- replicate( n = B,sampling,simplify = F)
      s <- lapply(s,create_data,p = i,sigma_e = j)
      s <- lapply(s, multi_fun)
      s_total <- cbind(s_total,s)
    }
  }
    return(s_total)
}

gene <- simulation(sampling,p,sigma_list,50)
l <- c(paste0("p = ",10, ",sigma = ",1),paste0("p = ",10, ",sigma = ",2),
      paste0("p = ",10, ",sigma = ",6),paste0("p = ",10, ",sigma = ",9),
      paste0("p = ",20, ",sigma = ",1),paste0("p = ",20, ",sigma = ",2),
      paste0("p = ",20, ",sigma = ",6),paste0("p = ",20, ",sigma = ",9),
      paste0("p = ",50, ",sigma = ",1),paste0("p = ",50, ",sigma = ",2),
      paste0("p = ",50, ",sigma = ",6),paste0("p = ",50, ",sigma = ",9))

k_sh_p <- c(rep(10,4),rep(20,4),rep(50,4))
k_col_sig <- rep(sigma_list,3)
```


### Q6
Compute the average accuracy and the standard-error for each (p, σ2). Display these in a figure and a
table.

```{r,warning= False, message=FALSE}
temp <- NULL
temp2 <- NULL

for(i in 1:12){
  df <- gene[,i]
  df <- rbindlist(lapply(df, as.data.frame.list))
  colnames(df) <- c("accurancy", "run.time")
  temp2 <- rbind(temp2,list(df))
  df <- round(c(avg = mean(df$accurancy),sd_accurancy = sd(df$accurancy)/sqrt(50)),3)
  temp <- rbind(temp,df)
}
names(temp2) <- l
row.names(temp) <- l
```


```{r}
temp <- as.data.frame(temp)
temp <- cbind(temp,k_col_sig,k_sh_p)

```

```{r}
temp <- as.data.frame(temp)
ggplot(temp,aes( y = avg,x=factor(k_col_sig))) +
  geom_bar(stat="identity",position="dodge") +
  facet_grid(~factor(k_sh_p))+
  geom_errorbar(data = temp,aes(ymin=avg-sd_accurancy,
  ymax=avg + sd_accurancy), width=.2,position=position_dodge(.9)) + 
    geom_text(aes(label=avg), vjust=1.6, color="white", size=3.5)+
  facet_grid(~factor(k_sh_p))+ theme_light()  +
  xlab("Devided by p level")+
  ylab("Accurancy Average") +
  ggtitle(label = "Averege Bar plot", subtitle = "Caculated over 50 simulations. Displayed by the different sigmas and p with standard error bar") +
  theme(plot.title = element_text(hjust = 0.5,size = 20, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5,size = 10, face = "bold")) +
  theme(legend.title = element_text(color = "black", size = 10),
          legend.text = element_text(color = "black")) +
  labs(shape="Vectors Variables \n Number", colour="SE of \n the Vectors") + ylim(c(0,1))




```


```{r}

#kable(temp) %>% kable_styling()
```


```{r}
temp2 <-bind_rows(temp2, .id = "column_label")
k_sh_p <- c(rep(10,4*50),rep(20,4*50),rep(50,4*50))
k_col_sig <- rep(rep(sigma_list, each = 50),3)
temp2 <- cbind(temp2,k_col_sig,k_sh_p)

ggplot(temp2, aes(x = run.time, y = accurancy, color =factor(k_sh_p) )) +
  geom_point(position = position_jitter(w = 0.001))+ facet_wrap(~factor(k_col_sig))+ theme(legend.position = "none") +
    theme_gray()  + ylim(c(0,1)) +
  ylab("Accurancy of K-means")+ xlab("Run time for K-mean convergence") +
  ggtitle(label = "Run time vs Accurancy", subtitle = "Displayed diffrant sigmas and p.") +   theme(plot.title = element_text(hjust = 0.5,size = 20, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5,size = 10, face = "bold"))
```
```{r}
ggplot(temp2, aes(y = run.time, x =factor(k_col_sig))) + facet_grid(~factor(k_sh_p))+
  geom_point(size = 1,alpha = 0.6) + 
  stat_summary(geom = "point",
    fun = "mean", col = "red",size = 1, fill = "red") +
  theme(legend.position = "none") + 
    theme_light() + ylim(c(0,0.002))+
  xlab("")+ ylab("Run time for K-mean convergence") +
  ggtitle(label = "Run time vs Accurancy", subtitle = "Displayed diffrant sigmas and p.") +
  theme(plot.title = element_text(hjust = 0.5,size = 20, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5,size = 10, face = "bold")) +
  theme(axis.text.x = element_text(angle = 00, vjust = 0.5))

```

# **2. Comparing demographic and election data:**

```{r, message=F, error=F, warning=F}
#load the data frames
knesset_df <- read.csv("C:/Users/Shahar/Dropbox/zugi/lemida/knesset_24.csv", encoding = "UTF-8")
CBS_df <- read_excel("C:/Users/Shahar/Dropbox/zugi/lemida/t01.xls")
```

### Q1

In this question we sampled 20 different locations that we would like to investigate.
We used the socio economic data from 2013 from the ISB website for the socio economic data and the 24 election results data.

```{r,message=F}
#first, we merge the data frames to find the matching locations in both. 
merged_df <- left_join(CBS_df, knesset_df, by = "סמל.ישוב")

#add "שם.ישוב" coloumn to the CBS data frame 
names_df <- as.data.frame(knesset_df[,2:3])
CBS_df <- left_join(CBS_df, names_df)

#semple 20 locations 
set.seed(20)
Semp_20 <- sample(merged_df$"סמל.ישוב" , 20)

# sum all the votes for each location 
#calculate the persents of votes for each party in every location 
knesset_df_norm <- knesset_df %>%rowwise %>% mutate(total_votes = sum(c_across( 8:46))) %>% ungroup() %>%  mutate(round(across(8:46, ~ . / total_votes),3))

#filter each data frame for the sempled values.
knesset_semp20 <- filter(knesset_df_norm, knesset_df_norm$"סמל.ישוב" %in% Semp_20)
CBS_semp20 <- filter(CBS_df, CBS_df$"סמל.ישוב" %in% Semp_20) 
```


### Q2

```{r}
knesst_dist <- knesset_semp20[,c(8:46)] %>% dist %>% hclust(method = "complete")
knesst_dend <- as.dendrogram(knesst_dist)
labels(knesst_dend) <- as.character(knesset_semp20$'שם.ישוב')

Knesst_plot <- ggplot(knesst_dend %>% 
                        set('branches_lwd', 0.7) %>%
                        set('labels_cex', 0.8),
                        horiz = TRUE) + 
                    ggtitle("Hirarchical tree of the 24 election datas with complete linked algorithm", "*Each color present diffrent cluster")

Knesst_plot
```


### Q3

```{r}
CBS_dist <- CBS_semp20[,6:17] %>% scale %>% dist %>% hclust(method = "complete")
CBS_dend <- as.dendrogram(CBS_dist)
labels(CBS_dend) <- as.character(CBS_semp20$'שם.ישוב')

CBS_plot <- ggplot(CBS_dend %>% 
                     set('branches_lwd', 0.7) %>% 
                     set('labels_cex', 0.8), horiz = TRUE) + 
                  ggtitle("Hirarchical tree of the CBS datas with complete linked algorithm", "*Each color present diffrent cluster")

CBS_plot
```


### Q4

In this question we tried to visualized the diffrents between the two dendograms.

Even before we see the visual comparison we tend to think that while there are some cities that have received a similar characterization in the two dendograms, yet most cities get a different height and sometimes completely opposite from the height they received in the other dendogram.

```{r}
dl <- dendlist(highlight_branches_col(knesst_dend), highlight_branches_col(CBS_dend))

tanglegram(dl, sort = TRUE, common_subtrees_color_lines = FALSE, highlight_distinct_edges  = FALSE, highlight_branches_lwd = FALSE, main_left = "CBS", main_right = "Knesset") 
```

After examining the visual comparison between the trees we understand that our hypothesis is Almost right< most of the cities were given a different location in each tree and there appears to be no connection between the two trees 

However, this does not mean that one of the dendograms is incorrect, the reason for the large differences between the two is a different effect of socioeconomic status on the population in each city, in addition we should remember that the population in Israel is very far from being a homogeneous population. 


### Q5
In this question we were asked to choos score witch calculate the similarity between the two trees. 
We choose the 


בחרנו את המדד של בייקר גמה, המדד הזה בעצם בוחר שתי ערים ובודק מהו הסיכוי הגבוה ביותר שתחת מספר מסויים של אשכולות שתי הערי יהיו עדיין תחת אשכול מסויים.
המספר של האשכולות מוחזר ואז עושים את אותו הדבר עבור שתי הערים בעץ השני. 
עושים את זה אן מעל 2 פעמים, זא לכל הזוגות האפשריים בעץ.
שומרים את כל המסספרים שקיבלנו בשתי רשימות, אחת עבור כל עץ ואז עושם מתאם פירסון בין שתי קבוצות המספרים ומקבלים את הקורלציה בין העצים.


```{r, message=F, error=F, warning=F}
dend <- knesst_dend
dend1 <- CBS_dend

cor <- cor_bakers_gamma(dend,dend1)
cor

```

קיבלנו קורלציה קרובה מאוד ל0 בין שתי הדנדוגרמות. 
משמעות הדבר היא שכמעט ואין קש רבין שתי הדנדוגרמות. 


### Q6
בשאלה זו התבקשנו למצוא את ההתפלגות של המתאם בין העצים, נבצע מבחן פרמוטציה על העץ המייצג את תוצאות הבחירות. 
עבור כל פרמוטציה נחשב את הקורלציה בין העץ המקורי לעץ הנדגם החדש. 
השערת האפס הינה שבין :......

ייצרנו גרף של התוצאות שקיבלנו 

```{r, message=F, error=F, warning=F}
the_cor <- cor_bakers_gamma(dend,dend)

R <- 100
cor_bakers_gamma_results <- numeric(R)
dend_mixed <- dend
for(i in 1:R) {
   dend_mixed <- sample.dendrogram(dend_mixed, replace = FALSE)
   cor_bakers_gamma_results[i] <- cor_bakers_gamma(dend, dend_mixed)
}


plot(density(cor_bakers_gamma_results),
     main = "Baker's gamma distribution under H0",
     xlim = c(-1,1))
abline(v = 0, lty = 2)
abline(v = the_cor, lty = 2, col = 2)
legend("topleft", legend = c("cor"), fill = c(2,4))
title(sub = paste("One sided p-value:",
                  "cor =",  round(sum(the_cor < cor_bakers_gamma_results)/ R, 4)))
```



# **3. Exploratory analysis of RNA seq data:**

```{r, message=F, error=F, warning=F}

k_means_shiny <- function(k){
  data_prep <- scale(med_dat,T,T)
  data_prep[is.na(data_prep)] <- 0
  m_new <- as.data.frame(data_prep[sample(1:53,k),])
  c_t <- apply(data_prep,1 ,FUN = c_fun, m=m_new)
  m_old <- as.data.frame(data_prep[sample(1:53,k),])
  
  
  while(any(abs(m_new - m_old)) > 0.1){
  data_prep$cluster <- c_t
  print(class(data_prep))
  m_old <- m_new
  m_new <- data_prep %>% group_by(cluster) %>% summarise_all(.funs = c(mean="mean"))
  print(m_new)
  c_t <- data_prep[,-cluster]  %>% apply(1,FUN = c_fun,m = m_new)
  print(data_prep[,cluster])
  }
  return(data_prep[,cluster])
}

c_fun <- function(d,m){
  p <- sweep(m,2,d,FUN = "-")
  p <- as.data.frame(p)
  p <- p*p
  p <- as.matrix(apply(p,1, sum))
  p <- which.min(p)
  return(p)
}

k_means_shiny(15)
```


```{r}

med_dat <- read.delim('C:/Users/abig4/OneDrive/Documents/GitHub/Statistical-Learning_Lab_2/gtex_Kmeans/gtex.gct',
                      skip = 2 ,row.names=c(1) , header = TRUE)
#med_dat <- read.delim("C:/Users/Shahar/Documents/GitHub/Statistical-Learning_Lab_2/gtex_Kmeans/gtex.gct",
#                      skip = 2 ,row.names=c(1) , header = TRUE)
gen_names <- med_dat[, 1]
med_dat <- med_dat[,-1]
med_dat <- transpose(med_dat)


```