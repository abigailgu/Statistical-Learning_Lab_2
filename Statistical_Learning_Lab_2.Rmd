---
title: "Statistical Learning and Data Analysis 2021 - 52525"
author: 'Abigail Gutman and Shahar Shalom '
date: "18/5/2021"
output:
  html_document: default
  pdf_document: default
subtitle: Lab 2 - Elections and RNA-sequencing
editor_options: 
  chunk_output_type: inline
---
1 Simulation Study
1.1 The data generation process


```{r setup, include=FALSE, message=FALSE, warning=FALSE}
library('MASS')
library(data.table)
library(ggplot2)
library(kableExtra)
library(dplyr)
library(dendextend)
library(readxl)
library(fuzzyjoin)
library(stringr)
library(ggdendro)
library(factoextra)
```

# **1. Simulation Study:**

### Q1:
Generate the first 10 coordinates of each µj vector j = 1, ..,3
```{r, warning=FALSE}
options(scipen = 999)


ob <- cbind(rep(1,20),rep(2,30),rep(3,50))
sampling <- NULL
for (i in 1:10) {
first_10 <- rnorm(3,0,1) #mu
sampling <- rbind(sampling,first_10)
colnames(sampling) <- c(1:3)
}


```

```{r}
calculate.accuracy <- function(data, cluster_data)
{
  matching <- Map(function(data, cluster_data) { data %in% cluster_data }, data, cluster_data)
  tf <- unlist(matching, use.names=FALSE)
  return (sum(tf)/length(tf))
}
```


```{r}

multi_fun <- function(s){
  start.time <- Sys.time()
  model <- kmeans(s,3,1,algorithm = "Lloyd")
  end.time <- Sys.time()
  time.taken <- end.time - start.time
  accurancy <- model$cluster
  accurancy <- calculate.accuracy(accurancy,ob)
  return(list(accurancy,time.taken))
}

```

### Q2:
Write a function that outputs a simulated dataset of dimension (100 × p)
```{r}
create_data <- function(sampling, p, sigma_e){
  x_data <- NULL
  if(p >10){
  mu_num <- rep(0,(p - 10))
  mu <- cbind(mu_num, mu_num, mu_num)
  mu <- rbind(sampling,mu)
  mu <- as.data.frame(mu) 
  } else {
    mu <- as.data.frame(sampling)
  }
  d <- diag(sqrt(rep(sigma_e,p)))
  dat_a = mvrnorm(20,mu = mu[,1],Sigma=  d)
  dat_b = mvrnorm(30,mu = mu[,2],Sigma=  d)
  dat_c = mvrnorm(50,mu = mu[,3],Sigma=  d)
  x_data = rbind(dat_a, dat_b,dat_c)
  return(x_data)
}
```

### Q3
Choose 4 levels of σ^2 and use p = 10, 20, 50.
choosing sigma : 1,7,150,212

### Q4
For each combination of σ^2 and p, generate multiple datasets (say B = 50).

### Q5
For each data-set, run K-means once on the p dimensional data, and save accuracy and
run-time.
```{r, warning=FALSE}
sigma_list <- c(1,7,150,212)
p <- c(10,20,50)
simulation <- function(sampling,p,sigma_list,B){
  s_total <- NULL
  for (i in p) {
    for (j in sigma_list) {
      s <- NULL
      s <- replicate( n = B,sampling,simplify = F)
      s <- lapply(s,create_data,p = i,sigma_e = j)
      s <- lapply(s, multi_fun)
      s_total <- cbind(s_total,s)
    }
  }
    return(s_total)
}

gene <- simulation(sampling,p,sigma_list,50)
l <- c(paste0("p = ",10, ",sigma = ",1),paste0("p = ",10, ",sigma = ",7),
      paste0("p = ",10, ",sigma = ",150),paste0("p = ",10, ",sigma = ",212),
      paste0("p = ",20, ",sigma = ",1),paste0("p = ",20, ",sigma = ",7),
      paste0("p = ",20, ",sigma = ",150),paste0("p = ",20, ",sigma = ",212),
      paste0("p = ",50, ",sigma = ",1),paste0("p = ",50, ",sigma = ",7),
      paste0("p = ",50, ",sigma = ",150),paste0("p = ",50, ",sigma = ",212))
```


### Q6
Compute the average accuracy and the standard-error for each (p, σ2). Display these in a figure and a
table.

```{r,warning= False, message=FALSE}
temp <- NULL
temp2 <- NULL

for(i in 1:12){
  df <- gene[,i]
  df <- rbindlist(lapply(df, as.data.frame.list))
  colnames(df) <- c("accurancy", "run.time")
  temp2 <- rbind(temp2,list(df))
  df <- round(c(avg = mean(df$accurancy),sd_accurancy = sd(df$accurancy)),3)
  temp <- rbind(temp,df)
}
names(temp2) <- l
row.names(temp) <- l
```


```{r}
temp <- as.data.frame(temp)
ggplot(temp,aes(x = sd_accurancy, y = avg)) + geom_point()

```

```{r}
#kable(temp) %>% kable_styling()
```

```{r}
temp2 <-bind_rows(temp2, .id = "column_label")
ggplot(temp2, aes(x = run.time, y = accurancy, group = column_label, col = column_label)) + geom_point() + facet_wrap(~column_label)+ theme(legend.position = "none")
```




# **2. Comparing demographic and election data:**

```{r, message=F, error=F, warning=F}
#load the data frames
knesset_df <- read.csv("C:/Users/Shahar/Dropbox/zugi/lemida/knesset_24.csv", encoding = "UTF-8")
CBS_df <- read_excel("C:/Users/Shahar/Dropbox/zugi/lemida/t01.xls")
```

### Q1

In this question we have sampled 20 different locations that we would like to investigate.
We used the socio economic data from 2013 from the ISB website. 

```{r,message=F}
#first, we merge the data frames to find the matching locations in both. 
merged_df <- left_join(CBS_df, knesset_df, by = "סמל.ישוב")

#add "שם.ישוב" coloumn to the CBS data frame 
names_df <- as.data.frame(knesset_df[,2:3])
CBS_df <- left_join(CBS_df, names_df)

#semple 20 locations 
Semp_20 <- sample(merged_df$"סמל.ישוב" , 20)

# sum all the votes for each location 
#calculate the persents of votes for each party in every location 
knesset_df_norm <- knesset_df %>%rowwise %>% mutate(total_votes = sum(c_across( 8:46))) %>% ungroup() %>%  mutate(round(across(8:46, ~ . / total_votes),3))

#filter each data frame for the sempled values.
knesset_semp20 <- filter(knesset_df_norm, knesset_df_norm$"סמל.ישוב" %in% Semp_20)
CBS_semp20 <- filter(CBS_df, CBS_df$"סמל.ישוב" %in% Semp_20) 
```


### Q2

הסיבה לשימוש באלגוריתם סינגל היא שאנחנו רוצות למצוא אשכולות של ערים אשר קרובות אחת לשניה מבחינת אופי פיזור הקולות בעיר. 
```{r}
knesst_dist <- knesset_semp20[,c(8:46)] %>% dist %>% hclust(method = "single")
knesst_dend <- as.dendrogram(knesst_dist)
labels(knesst_dend) <- knesset_semp20$'שם.ישוב'

Knesst_plot <- ggplot(knesst_dend %>% set('branches_k_color', k = 4) %>%
                set('branches_lwd', 0.7) %>%
                set('labels_colors', k = 4) %>%
                set('labels_cex', 0.8), 
                horiz = TRUE) 
# Knesst_plot
```

### Q3

גם כאן בחרנו להריץ את אלגוריתם סינגל.
בחרנו לבצע חלוקה לאשכולות על פי רמת החיים של התושבים בעיר


```{r}
living_stand_dist <- CBS_semp20[which(colnames(CBS_semp20) %in% c('income', 'motorization','avgvehicle','avg_abroad'))]

CBS_dist <- living_stand_dist %>% scale %>% dist %>% hclust(method = "single")
CBS_dend <- as.dendrogram(CBS_dist)
labels(CBS_dend) <- CBS_semp20$'שם.ישוב'

CBS_plot <- ggplot(CBS_dend %>% set('branches_k_color', k = 4) %>%
                set('branches_lwd', 0.7) %>%
                set('labels_colors', k = 4) %>%
                set('labels_cex', 0.8), 
                horiz = TRUE) 

# CBS_plot
```


### Q4
#כאן צריך לכתוב על קווי דמיון ושוני בין שתי הדנדוגרמות 
```{r}

dend_list <- dendlist(knesst_dend, CBS_dend) %>%  untangle() %>% tanglegram()



```

### Q5
```{r, message=F, error=F, warning=F}

```


### Q6
```{r, message=F, error=F, warning=F}

```



# **3. Exploratory analysis of RNA seq data:**

```{r, message=F, error=F, warning=F}
library(dplyr)
library(data.table)
k_means_shiny <- function(k){
  data_prep <- scale(med_dat,T,T)
  m_new <- sample_n(med_dat,k)
  c_t <- lapply(data_prep ,FUN = c_fun, m=m_new)
  print(c_t)
  
  
  #while(any(abs(m_new - m_old)) > 0.001){
  #data_prep["cluster"] <- c_t
  #m_old <- m_new
  #m_new <- data_prep %>% group_by(cluster) %>% summarise(mean)
  #c_t <- data_prep[,!"cluster"]  %>% lapply(FUN = c_fun,m = m_new)
  #print(data_prep[,"cluster"])
  #}
  #return(data_prep[,"cluster"])
}

c_fun <- function(d,m){
  print(d)
  p <- (m - d)**2
  p <- lapply(p,sum)
  p <- lapply(p,which.min)
  #return(which.min(p))
  #print(p)
}

med_dat <- read.delim('C:/Users/abig4/OneDrive/Documents/GitHub/Statistical-Learning_Lab_2/gtex_Kmeans/gtex.gct',
                      skip = 2 ,row.names=c(1) , header = TRUE)
gen_names <- med_dat[, 1]
med_dat <- med_dat[,-1]
med_dat <- transpose(med_dat)



k_means_shiny(15)

```